---
title: "SONYC-UST-V2: An Urban Sound Tagging Dataset with Spatiotemporal Context"
collection: publications
permalink: /publication/2020-09-11-dcase-2020
excerpt: 'We present SONYC-UST-V2, a dataset for urban sound tagging with spatiotemporal information. This dataset is aimed for the development and evaluation of machine listening systems for real-world urban noise monitoring. While datasets of urban recordings are available, this dataset provides the opportunity to investigate how spatiotemporal metadata can aid in the prediction of urban sound tags. SONYC-UST-V2 consists of 18510 audio recordings from the&quot; Sounds of New York City&quot;(SONYC) acoustic sensor network, including the timestamp of audio acquisition and location of the sensor. The dataset contains annotations by volunteers from the Zooniverse citizen science platform, as well as a two-stage verification with our team. In this article, we describe our data collection procedure and propose evaluation metrics for multilabel classification of urban sound tags. We report the results of a simple baseline model that exploits spatiotemporal information.'
date: 2020-09-11
venue: 'Detection and Classification of Acoustic Scenes and Events 2020'
paperurl: 'https://arxiv.org/pdf/2009.05188.pdf'
citation: 'Cartwright, M., Cramer, J., Mendez, A. E. M., Wang, Y., Wu, H. H., Lostanlen, V., ... &amp; Bello, J. P. (2020). SONYC-UST-V2: An Urban Sound Tagging Dataset with Spatiotemporal Context. Proceedings of the Detection and Classification of Acoustic Scenes and Events 2020 Workshop (DCASE2020)'
---
We present SONYC-UST-V2, a dataset for urban sound tagging with spatiotemporal information. This dataset is aimed for the development and evaluation of machine listening systems for real-world urban noise monitoring. While datasets of urban recordings are available, this dataset provides the opportunity to investigate how spatiotemporal metadata can aid in the prediction of urban sound tags. SONYC-UST-V2 consists of 18510 audio recordings from the&quot; Sounds of New York City&quot;(SONYC) acoustic sensor network, including the timestamp of audio acquisition and location of the sensor. The dataset contains annotations by volunteers from the Zooniverse citizen science platform, as well as a two-stage verification with our team. In this article, we describe our data collection procedure and propose evaluation metrics for multilabel classification of urban sound tags. We report the results of a simple baseline model that exploits spatiotemporal information.

[Download paper here](https://arxiv.org/pdf/2009.05188.pdf)

Recommended citation: Cartwright, M., Cramer, J., Mendez, A. E. M., Wang, Y., Wu, H. H., Lostanlen, V., ... & Bello, J. P. (2020). SONYC-UST-V2: An Urban Sound Tagging Dataset with Spatiotemporal Context. Proceedings of the Detection and Classification of Acoustic Scenes and Events 2020 Workshop (DCASE2020)